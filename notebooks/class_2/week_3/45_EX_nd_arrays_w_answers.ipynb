{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Week 3 Quiz\n",
                "\n",
                "\n",
                "**Note**: \n",
                "\n",
                "> This exercise has been written out in something called a Jupyter Notebook. We'll discuss Jupyter Notebooks in more detail later in the course—they are very a powerful tool for data science communication!—but for the time being, the notebook is just a convenient way for us to write out the exercise. You don't need to *do* anything with the notebook except read its contents—just use write your Python code in a regular `.py` file.\n",
                "\n",
                "As previously discussed, we frequently use matrices and data science because they are a natural format for representing data generated by collecting the same type of information from numerous entities. For example, below is a toy dataset that you could imagine was created by collecting information about employees at a company—each column is a different type of information being collected (income, age, years of education), and each row is the information about a different employee.\n",
                "\n",
                "In the following questions, you will be asked to answer a number of questions about this toy dataset. As with other exercises in this class, you will find the directions for this graded exercise here, but please submit your actual answers in the graded quiz."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[ 22000,     20,     12],\n",
                            "       [ 65000,     35,     16],\n",
                            "       [ 19000,     55,     11],\n",
                            "       [110000,     35,     22],\n",
                            "       [ 14000,     21,     12],\n",
                            "       [ 12000,     19,      8],\n",
                            "       [ 35000,     42,     12]])"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import numpy as np\n",
                "\n",
                "incomes = [22_000, 65_000, 19_000, 110_000, 14_000, 12_000, 35_000]\n",
                "ages = [20, 35, 55, 35, 21, 19, 42]\n",
                "years_of_education = [12, 16, 11, 22, 12, 8, 12]\n",
                "\n",
                "survey = np.array([incomes, ages, years_of_education]).T\n",
                "survey\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Summarizing Data\n",
                "\n",
                "1. What is the average (mean) age of all employees (rounded to 1 decimal place)?\n",
                "2. What is the average (mean) income of employees over 30 (rounded to 1 decimal place)?\n",
                "3. What is the average (mean) number of years of education for employees with incomes above the average income of all employees (rounded to 1 decimal place)?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "32.4"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mean_age = np.mean(survey[:, 1])\n",
                "np.round(mean_age, 1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "57250.0"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mean_income_over30 = np.mean(survey[survey[:, 1] > 30, 0])\n",
                "mean_income_over30"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "57250.0"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(mean_income_over30, 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "39571.42857142857"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mean_income = np.mean(survey[:, 0])\n",
                "mean_income\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "39571.4"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(mean_income, 1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "19.0"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mean_education = np.mean(survey[survey[:, 0] > mean_income, 2])\n",
                "mean_education"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "19.0"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(mean_education, 1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## Part 2: Editing Data\n",
                "\n",
                "The US government is thinking about offering a 1,500 tax credit to anyone making less than 20,000 a year. You can think of this tax credit as effectively an additional $1,500 of income to each person receiving the credit.\n",
                "\n",
                "4. Using the data from `survey`, modify income values to calculate a new estimate of the employees' incomes after we take this credit into account. What will the average income be for all employees if those making less than 20,000 a year were to receive this credit (rounded to 1 decimal place)?\n",
                "    - Do so by subsetting and editing values programmatically, *not* just typing values by hand. (Yes, writing out a new vector by hand is easy to do in this example, but you couldn't do it with a large, real dataset!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[ 22000,     20,     12],\n",
                            "       [ 65000,     35,     16],\n",
                            "       [ 20500,     55,     11],\n",
                            "       [110000,     35,     22],\n",
                            "       [ 15500,     21,     12],\n",
                            "       [ 13500,     19,      8],\n",
                            "       [ 35000,     42,     12]])"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "survey[survey[:, 0] < 20_000, 0] = survey[survey[:, 0] < 20_000, 0] + 1_500\n",
                "survey\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "40214.3"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(np.mean(survey[:, 0]), 1)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: Measuring Income Inequality (with Real Data!)\n",
                "\n",
                "In this exercise, we'll be working with data from the [US Current Population Survey, provided by the National Bureau of Economic Research (NBER)](https://www.nber.org/research/data/current-population-survey-cps-merged-outgoing-rotation-group-earnings-data). This is a regular survey conducted by the US Bureau of Labor to calculate the US employment rate.\n",
                "\n",
                "In this exercise, we'll use this data to study gender and racial wage inequality in the US.\n",
                "\n",
                "Load data from the 2018 CPS survey with the following command:\n",
                "\n",
                "```python\n",
                "cps = np.loadtxt(\"data/cps.txt\")\n",
                "```\n",
                "\n",
                "This data is a *subset* of the full CPS survey and contains only data on **employed respondents working at least 35 hours a week (e.g., full-time).**\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "5. How many rows does this matrix have?\n",
                "\n",
                "6. The five columns of this matrix correspond to:\n",
                "    - Column 1: Weekly income in dollars.\n",
                "    - Column 2: Usual hours respondent works per week.\n",
                "    - Column 3: Gender. 2 is \"Female\", 1 is \"Male\"\n",
                "    - Column 4: Race. This can take on a lot of values for those who identify as mixed race, but for simplicity, in this exercise, we'll just focus on a few values. For those interested, the full set of codes can be found on page 19 of the [CPS codebook](https://data.nber.org/morg/docs/cpsx.pdf).\n",
                "        - 1: White\n",
                "        - 2: Black\n",
                "        - 3: American Indian\n",
                "        - 4: Asian only\n",
                "        - 5: Hawaiian/Pacific Islander only\n",
                "    - Column 5: Survey weights.\n",
                "\n",
                "Note that race does not break out Hispanic / non-Hispanic identities. In US government surveys, Hispanic / non-Hispanic is usually recorded in a separate `ethnicity` variable, so many people who identify as Hispanic are identified as White or Black in the `race` variable.\n",
                "\n",
                "For the moment, let's ignore survey weights—they don't impact results here significantly.\n",
                "\n",
                "**What is the *average hourly wage* for all workers in this data (round it to one decimal place)?**\n",
                "\n",
                "**Hint:** This will require more than just using `mean` on a single column!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "7. What is the average hourly wage of working men (rounded to one decimal place)? \n",
                "\n",
                "8. What is the average hourly wage of working women (rounded to one decimal place)?\n",
                "\n",
                "9.  What share (e.g., a value between 0 and 1) of men's average hourly wage is women's average hourly wage? (rounded to three decimal places). In other words, what is women's average hourly wage divided by men's average hourly wage? *Don't round anything until you have your final answer!*\n",
                "\n",
                "Congratulations! You've just calculated the US gender wage gap, on your own, using real data! I mean... I guess \"congratulations\" is a weird thing to say after directly measuring one of the more egregious inequities in US society, but one of the reasons many of us study data science is so that we will have the ability to directly measure these types of phenomena in the hopes of being able to better understand and address them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(122603, 5)"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "cps = np.loadtxt(\"data/cps.txt\")\n",
                "cps.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "26.0"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "hourly = cps[:, 0] / cps[:, 1]\n",
                "np.round(np.mean(hourly), 1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "27.883329990399556"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "men = np.mean(hourly[cps[:, 2] == 1])\n",
                "men\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "27.9"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(men, 1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "23.803157653012704"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "women = np.mean(hourly[cps[:, 2] == 2])\n",
                "women\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "23.8"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(women, 1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8536698328789393"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "women / men\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.854"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(women / men, 3)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "10.  Now, speaking of egregious inequities, what is the average hourly wage for respondents who identify as Black (rounded to one decimal place)?\n",
                "\n",
                "11.  What is the average hourly wage for respondents who identify as White (rounded to one decimal place)?\n",
                "\n",
                "12.  What share (e.g., a value between 0 and 1) of respondents who identify as White's average hourly wage is respondents who identify as Black's average hourly wage? (rounded to three decimal places). In other words, what is the respondents who identify as Black's average hourly wage divided by respondents who identify as White's average hourly wage? *Don't round anything until you have your final answer!*\n",
                "\n",
                "Note that this will only be an approximation—one would normally also include all respondents of mixed-race into non-mutually exclusive categories like \"Any Part Black\" or \"Any Part White\", and we would also break out Hispanic and non-Hispanic respondents. But as most respondents only pick on racial category, this will still give us a reasonable approximation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "21.540126529947035"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "black = np.mean(hourly[cps[:, 3] == 2])\n",
                "black\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "21.5"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(black, 1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "26.397643062830547"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "white = np.mean(hourly[cps[:, 3] == 1])\n",
                "white\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "26.4"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(white, 1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8159867333109302"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "black / white\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.816"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(black / white, 3)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bonus Question\n",
                "\n",
                "As noted above, the fifth column of our data contains something called \"sampling weights.\" That's because when the government conducted this survey, they didn't draw a random sample of respondents from the US population where everyone had the same probability of being interviewed. As a result, when we calculate the average hourly wage of the people in the survey, it isn't *quite* the best estimate we have for the average hourly wage for everyone working in the United States. To calculate this number as accurately as possible, we have to take into account the fact that some respondents in the data were more likely to be included than others, and thus can be thought of as standing in for a smaller group of people in the US.\n",
                "\n",
                "Why would the government do this? The main reason is that if we want to make statements about a group in a survey like this, the accuracy of those statements will depend on the number of individuals who have actually ended up taking the survey. If we are interested in a big group—like White men—we are almost guaranteed to have enough of them in any reasonably sized survey to be able to make accurate statements about that subpopulation. But if we were interested in the life experiences of, say, people in their twenties who have a high school diploma but never attended college, and who live in rural communities, we may have to make a deliberate effort to ensure that there are more of those people in our survey than when we would get if we just took a random sample where everyone in the United States had the same probability of being included.\n",
                "\n",
                "As I mentioned above, for the questions above, the sampling weights don't make a very big difference to our answers, but the way to get the *most accurate* estimates would be to take them into account. So let's give that a try!\n",
                "\n",
                "When we calculate the average of a variable, we do so by multiplying all the values of the variable by $1/N$ (where $N$ is the number of observations we have) and then adding up those multiplied values.\n",
                "\n",
                "For a *weighted* average, we take the value for each observation $i$ and multiply it by\n",
                "\n",
                "$$weight_i / \\sum_{j=1}^N weights_j$$\n",
                "\n",
                "where $weight_i$ is the observation's weight, and $\\sum_{j=1}^N weights_j$ is the total of all the weights in the population being averaged. Then we just add up those values!\n",
                "\n",
                "Given that, what is the average hourly wage of Americans working full-time jobs (i.e., the group in this survey) taking into account survey weights (rounded to **two** decimal places)?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "true_average = np.sum((hourly * cps[:, 4]) / np.sum(cps[:, 4]))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "25.93"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(true_average, 2)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.6 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "718fed28bf9f8c7851519acf2fb923cd655120b36de3b67253eeb0428bd33d2d"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
