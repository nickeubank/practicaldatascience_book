{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: code your own KNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn! In this exercise, you'll complete the KNN classifier class below. Skeleton code is provided and we'll discuss some strategies for constructing the largest method of the class, `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Knn_classification:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Knn class\n",
    "        self.x_train: training data\n",
    "        self.y_train: training labels\n",
    "        \"\"\"\n",
    "        # Save the training data to properties of this class\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Save the training data to properties of this class\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: training data\n",
    "        y: training labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def predict(self, x, k):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the provided data\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: data to classify\n",
    "        k: number of neighbors to use\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array(y_hat): array of predicted class labels\n",
    "        \"\"\"\n",
    "\n",
    "        y_hat = []  # Variable to store the estimated class labels\n",
    "    \n",
    "        # Calculate the distance from each vector in x to the training data\n",
    "            # - Loop through each of the samples for which we wish to make predictions\n",
    "            #   - For each sample, calculate the Euclidean distance to every training sample\n",
    "            #   - Determine the k nearest samples\n",
    "            #   - Determine which class of the k nearest observations was most prevalent and assign that label\n",
    "            # - Append the assigned label to y_hat\n",
    "\n",
    "        # Return the estimated targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `fit()`\n",
    "Start by completing the `fit` function. Here, you're simply storing the training data for later comparison during prediction.\n",
    "\n",
    "## 2. `predict()`\n",
    "Next, we'll walk through `predict`. There are three main steps as you loop through observations for which you're creating predictions:\n",
    "1. For each sample, calculate the Euclidean distance to every training sample (`get_distance()`)\n",
    "2. Determine the k nearest samples (`get_nearest()`)\n",
    "3. Determine which class of the k nearest observations was most prevalent and assign that label as the prediction (`get_most_frequent_class()`)\n",
    "\n",
    "By breaking the larger method into these three smaller steps, we can create and test functions that do each of these. To help you work through it, we'll provide you with inputs and outputs for each function and then you'll piece them together in the final method as part of the skeleton code above.\n",
    "\n",
    "### 2.1. `get_distance()`\n",
    "\n",
    "**Goal:** For each observation, calculate the Euclidean distance to every training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(x,X_train):\n",
    "    \"\"\"\n",
    "    Compute the distance between one observation and a set of observations\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: observation with M features [size M]\n",
    "    X_train: collection of N observations to compare against [size N x M]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Array of Euclidean distances between x and each observation in X_train\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a test case to help you with 2.1, below. We'll share one test case for each component of `predict`, although these are not exhaustive tests, you may want to test your functions further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "x = np.array([0, 1])\n",
    "X_train = np.array([[0,0],[1,1],[2,2]])\n",
    "\n",
    "out = get_distance(x,X_train)\n",
    "out\n",
    "\n",
    "# Outputs\n",
    "correct_output = np.array([1, 1, 5])\n",
    "if np.array_equal(get_distance(x,X_train), correct_output): print(\"PASSED\")\n",
    "else: print(\"FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this and every function, make sure you **always** check the dimensions of each array that you use as inputs to this and every function you write. Sometimes the input is not what you expected so it's best to take a moment to check and make sure you know what the input dimensions are. This can be tricky, as we'll discuss more in the next function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. `get_nearest()`\n",
    "**Goal**: Determine the k nearest samples based on the distances you calculated in `get_distance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest(dist,k,labels):\n",
    "    \"\"\"\n",
    "    Gets the labels of the k nearest labels by distance\n",
    "    Parameters\n",
    "    ----------\n",
    "    dist: Euclidean distance observation to each training observation (from `get_distance`) [size N]\n",
    "    k: number of neighbors to identify [scalar]\n",
    "    labels: corresponding training data labels for each observation that was \n",
    "        compared when computing `dist` using `get_distance` [size N]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The target variable class of the k nearest neighbors [size k]\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a test case to help you with 2.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "dist = np.array([0,6,2,78,3,7,8])\n",
    "k = 3\n",
    "labels = np.array(['elephant', 'giraffe', 'tiger', 'lion', 'eagle', 'mouse', 'skunk'])\n",
    "\n",
    "# Outputs\n",
    "output = get_nearest(dist,k,labels)\n",
    "correct_output = np.array(['elephant', 'tiger', 'eagle'])\n",
    "if np.array_equal(output, correct_output): print(\"PASSED\")\n",
    "else: print(\"FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to keep in mind with this function.\n",
    "\n",
    "First, make sure you **always** check the dimensions of each array that you use as inputs to these functions. This can lead to a common error. Numpy arrays that represent a vector can be represented as two-dimensional arrays with a size of `(N,1)` or sometimes just a one-dimensional array with a size given as (N,). These are not always compatible with one another and can lead to unexpected results if you don't make sure the dimensions are the same beforehand. It's easy to go from size `(N,1)` to size `(N,)` by using the `np.squeeze()` method.\n",
    "\n",
    "Secondly, note that the order of the values in the numpy array must be the same for both the distance and label arrays. If not, the label won't correspond to the distance measure.\n",
    "\n",
    "Lastly, consider what happens if the distances are the same. What if you're calculating the $k=3$ nearest neighbors and the shortest 5 distances to training samples are, $[0.1,0.2,0.3,0.3.0.4]$? In that case, there's a tie for the third nearest neighbor? This may be uncommon, but it could happen. There are a few ways to resolve this. To keep this simple, if there is a tie, randomly select between the labels that correspond to the equidistant training observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. `get_most_frequent_class()`\n",
    "\n",
    "**Goal:** Determine which class of the k nearest observations was most prevalent from `get_nearest` which is the label that will be assigned as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent_class(labels):\n",
    "    \"\"\"\n",
    "    Gets the most frequent class label of the k nearest neighbors\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: categorical training data labels for each observation that was \n",
    "        identified as one of the k nearest training data observations [size k]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The target variable class of the k nearest neighbors [scalar]\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a test case to help you with 2.3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "labels = np.array(['elephant', 'elephant', 'tiger', 'tiger', 'eagle', 'tiger', 'skunk'])\n",
    "\n",
    "# Outputs\n",
    "output = get_most_frequent_class(labels)\n",
    "correct_output = 'tiger'\n",
    "if output == correct_output: print(\"PASSED\")\n",
    "else: print(\"FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you have a tie? For example, imagine you're applying KNN with $k=5$ and the labels of the nearest 5 training observations to the observation that you're making a prediction for are: `['elephant', 'elephant', 'tiger', 'tiger', 'eagle']`. In this case there is a tie between elephant and tiger. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each of the three above pieces complete, you should be able to connect the three of them together and place them inside a loop to complete the `predict` function of the `Knn_classification` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test your code\n",
    "\n",
    "With your KNN class complete, it's time to apply it to some real data! You'll apply this to the iris data that we split previously. \n",
    "\n",
    "3.1. Start by loading the training and test data we prepared previously as `train.csv` and `test.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_train = \n",
    "data_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. For the training and test data, create separate variables from your data for the features and target data. For the training data this would be `x_train` and `y_train` and for the test data, `x_test` and `y_test`. We recommend you save these as numpy arrays (which you can extract from a pandas dataframe using the `.values` property)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = \n",
    "y_train = \n",
    "\n",
    "x_test = \n",
    "y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3.3. With the data loaded - use the `fit` method of your KNN classifier to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNN model\n",
    "myknn = Knn_classification()\n",
    "\n",
    "# Train the model\n",
    "myknn.fit(COMPLETE_THE_INPUTS_HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. Once your model is trained use it to predict labels for your test data and call those predictions `y_predictions` using $k=5$ nearest neighbors. Look at your predictions to make sure they seem to be reasonable in terms of the right dimensions, be reflective of the potential predictive categories, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "\n",
    "y_prediction = myknn.predict(COMPLETE_THE_INPUTS_HERE)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3.5. Finally, using the predictions you made, compare your predictions to the target variable classes in the test dataset (`y_test`) and determine the accuracy of your model's predictions on  using the accuracy function we previously developed - and included below. Make sure to check the dimensions of your data in case one array is `(N,1)` and the other is `(N,)`; you can always use `np.squeeze()` to correct this discrepancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric of overall classification accuracy\n",
    "#  both y and y_hat should be numpy arrays\n",
    "def accuracy(y,y_hat):\n",
    "    nvalues = len(y)\n",
    "    accuracy = sum(y == y_hat) / nvalues\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare your predictions to the labels from the test data to evaluate accuracy on the test data\n",
    "accuracy(COMPLETE_THE_INPUTS_HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6. What was the overall accuracy on your test data? \n",
    "\n",
    "Congratulations! You've coded up your own prediction algorithm and used it to classify data! \n",
    "\n",
    "This is a big step and while it's worth taking a moment to celebrate, there's a lot of nuance here that we didn't explore in this exercise. First off, not every classification problem will work as well as this one. Accuracy will vary by problem and there are many problems far more challenging. Secondly, we used overall accuracy to evaluate our model's predictive performance, but that is a summary value. It's often important to know how well it predicted *each class* since it may work perfectly on some classes and poorly on others - overall accuracy may struggle under those conditions. \n",
    "\n",
    "With all of this, you've taken a step deeper into the world of programming, data science, and machine learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
