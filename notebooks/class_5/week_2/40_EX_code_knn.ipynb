{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: code your own KNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn! In this exercise, you'll complete the KNN classifier class below. Skeleton code is provided and we'll discuss some strategies for constructing the largest method of the class, `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Knn:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Knn class\n",
    "        self.x_train: training data\n",
    "        self.y_train: training labels\n",
    "        \"\"\"\n",
    "        # Save the training data to properties of this class\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Save the training data to properties of this class\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: training data\n",
    "        y: training labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def predict(self, x, k):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the provided data\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: data to classify\n",
    "        k: number of neighbors to use\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array(y_hat): array of predicted class labels\n",
    "        \"\"\"\n",
    "\n",
    "        y_hat = []  # Variable to store the estimated class labels\n",
    "    \n",
    "        # Calculate the distance from each vector in x to the training data\n",
    "            # - Loop through each of the samples for which we wish to make predictions\n",
    "            #   - For each sample, calculate the Euclidean distance to every training sample\n",
    "            #   - Determine the k nearest samples\n",
    "            #   - Determine which class of the k nearest observations was most prevalent and assign that label\n",
    "            # - Append the assigned label to y_hat\n",
    "\n",
    "        # Return the estimated targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by completing the `fit` function. Here, you're simply storing the training data for later comparison during prediction.\n",
    "\n",
    "Next, we'll walk through `predict`. There are three main steps as you loop through observations for which you're creating predictions:\n",
    "1. For each sample, calculate the Euclidean distance to every training sample\n",
    "2. Determine the k nearest samples\n",
    "3. Determine which class of the k nearest observations was most prevalent and assign that label as the prediction\n",
    "\n",
    "By breaking the larger method into these three smaller steps, we can create and test functions that do each of these. To help you work through it, we'll provide you with inputs and outputs for each function and then you'll piece them together in the final method as part of the skeleton code above.\n",
    "\n",
    "(1) For each sample, calculate the Euclidean distance to every training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(x,X_train):\n",
    "    \"\"\"\n",
    "    Compute the distance between one observation and a set of observations\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: observation with M features [size M]\n",
    "    X_train: collection of N observations to compare against [size N x M]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Array of Euclidean distances between x and each observation in X_train\n",
    "    \"\"\"\n",
    "    diff = X_train - x\n",
    "    return np.sum(diff**2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test case to help you with (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inputs\n",
    "x = np.array([0, 1])\n",
    "X_train = np.array([[0,0],[1,1],[2,2]])\n",
    "\n",
    "out = get_distance(x,X_train)\n",
    "out\n",
    "\n",
    "# Outputs\n",
    "correct_output = np.array([1, 1, 5])\n",
    "if np.array_equal(get_distance(x,X_train), correct_output): print(\"PASSED\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Determine the k nearest samples based on the distances you calculated in `get_distance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest(dist,k,labels):\n",
    "    \"\"\"\n",
    "    Gets the labels of the k nearest labels by distance\n",
    "    Parameters\n",
    "    ----------\n",
    "    dist: Euclidean distance observation to each training observation (from `get_distance`) [size N]\n",
    "    k: number of neighbors to identify [scalar]\n",
    "    labels: corresponding training data labels for each overservation that was \n",
    "        compared when computing `dist` using `get_distance` [size N]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The target variable class of the k nearest neighbors [size k]\n",
    "    \"\"\"\n",
    "    df_distance = pd.DataFrame({\n",
    "        'distance':dist, \n",
    "        'y':labels\n",
    "    })\n",
    "    df_sorted = df_distance.sort_values('distance')\n",
    "    return df_sorted['y'].iloc[0:k].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test case to help you with (2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elephant' 'tiger' 'eagle']\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Inputs\n",
    "dist = np.array([0,6,2,78,3,7,8])\n",
    "k = 3\n",
    "labels = np.array(['elephant', 'giraffe', 'tiger', 'lion', 'eagle', 'mouse', 'skunk'])\n",
    "\n",
    "# Outputs\n",
    "output = get_nearest(dist,k,labels)\n",
    "correct_output = np.array(['elephant', 'tiger', 'eagle'])\n",
    "if np.array_equal(output, correct_output): print(\"PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! Note size of the labels from the data (extra dimension)\n",
    "Note the order of the labels needs to be the same for both distance and labels - that can't be changed\n",
    "What happens if multiple distances are the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Determine which class of the k nearest observations was most prevalent from `get_nearest` which is the label that will be assigned as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent_class(labels):\n",
    "    \"\"\"\n",
    "    Gets the labels of the k nearest labels by distance\n",
    "    Parameters\n",
    "    ----------\n",
    "    dist: Euclidean distance observation to each training observation (from `get_distance`) [size N]\n",
    "    k: number of neighbors to identify [scalar]\n",
    "    labels: corresponding training data labels for each overservation that was \n",
    "        compared when computing `dist` using `get_distance` [size N]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The target variable class of the k nearest neighbors [size k]\n",
    "    \"\"\"\n",
    "    label_series = pd.Series(labels)\n",
    "    df = label_series.value_counts()\n",
    "    max_value = df.max()\n",
    "    options = df[df==max_value].index.values\n",
    "    return np.random.choice(options) # If there's one option, return it; else, pick one at random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test case to help you with (3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Inputs\n",
    "labels = np.array(['elephant', 'elephant', 'tiger', 'tiger', 'eagle', 'tiger', 'skunk'])\n",
    "\n",
    "# Outputs\n",
    "output = get_most_frequent_class(labels)\n",
    "correct_output = 'tiger'\n",
    "if output == correct_output: print(\"PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you have a tie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this out, you'll need to apply it to some data. You'll apply this to the iris data that we split previously. Let's start by loading our training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = \n",
    "data_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "import pandas as pd\n",
    "data_train = pd.read_csv(\"data/train.csv\")\n",
    "data_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded - use the `fit` method of your KNN classifier to train the model. Once your model is trained use it to predict labels for your test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the predictions you made, compare your predictions to the target variable class found in your test dataset and determine the accuracy of your model's predictions on the test data using the accuracy function we previously developed - and included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric of overall classification accuracy\n",
    "#  both y and y_hat should be numpy arrays\n",
    "def accuracy(y,y_hat):\n",
    "    nvalues = len(y)\n",
    "    accuracy = sum(y == y_hat) / nvalues\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
