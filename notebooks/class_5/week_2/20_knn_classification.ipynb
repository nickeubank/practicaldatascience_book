{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor Classification\n",
    "\n",
    "Let's jump into an algorithm for prediction: the K-Nearest Neighbor (KNN) classifier. The concept behind a KNN classifier is simple: to make a prediction for a set of inputs you've never seen before, find the K most similar sets of features from your training data and estimate the same class as the majority of its neighbors.\n",
    "\n",
    "Let's take a look at an example of this. Imagine we have 3 classes. To take a classic example imagine that we are trying to classify flowers based on measurements of their sepals and petals. In this case, the classes could be the specific type of flower, for example, class 1 may be \"Iris versicolor\", class 2 may be \"Iris verginica, and class 3 may be \"Iris setosa\". These are our output variables that we are trying to predict, our $y$ values. In this example, perhaps we have two features, or characteristics of each flower (each sample). For our features, we may measure petal width and sepal width.\n",
    "\n",
    "In this case, we could plot our training data as shown in the figure below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/knn0.png)\n",
    "\n",
    "*Figure 1. Feature space plot showing two features (e.g. sepal width and petal width) and three classes of data (e.g. three varieties of Irises).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This plot is called a feature space plot because the axes of the plot are each features of the data (e.g. sepal width and petal width). Each point represents *one* flower with its features identified by the axis values. Additionally, since this is training data, we know the class label for each flower, which is how each point is colored.\n",
    "\n",
    "Now, let's say we want to predict the class of two new samples for which we don't have labels, as shown in the figure below:\n",
    "\n",
    "![](img/knn1.png)\n",
    "\n",
    "*Figure 2. Feature space plot showing the labeled training data and unlabeled samples that we want to make predictions for.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we use the intuition that the flowers with similar sepal widths and petal widths are more likely than not to be of a similar class. In particular, we look at the $k$ nearest flowers and assign each unlabeled point to the most represented class amongst the $k$ neighbors.\n",
    "\n",
    "This process is shown below for the case of $k=5$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/knn2.png)\n",
    "\n",
    "*Figure 3. Feature space plot showing the $k=5$ nearest neighbors to each of the two previously unlabeled samples and the predicted label for each sample based on the most represented class among the $k$ neighbors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic intuition behind a KNN classifier. It has a few benefits: it's simple to implement and interpret and naturally handles classification with 2 or more classes. It also requires minimal training time.\n",
    "\n",
    "Now let's discuss how this algorithm works at an algorithmic level as we work towards building this ourselves. Here are the steps:\n",
    "\n",
    "Model training is the process of fitting the model to the data to help it to make as accurate of predictions for unlabeled data as possible. In this case, it has one simple step:\n",
    "1. Load and save the training data (features and the outputs we wish to predict). \n",
    "\n",
    "Model prediction is the process of making predictions for one or more samples of data for which we only input the features (not the corresponding outputs) since we assume that are trying to predict those outputs.\n",
    "1. Input the features of a sample for which we wish to make a prediction of the outputs\n",
    "2. Find the distance between the sample features and each of the training data sample features\n",
    "3. Identify the 5 closest samples in the training data to the input sample\n",
    "4. Determine which class is most prevalent among the 5 closest samples and assign that class to the sample\n",
    "5. Repeat steps 1-5 for each sample for which predictions are being made"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
