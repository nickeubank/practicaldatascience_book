{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Classifier Performance\n",
    "\n",
    "How can we evaluate how well our classifier is making predictions? The simplest way is to determine what fraction of the predictions on our test dataset are made correctly. Recall that we use our training dataset for fitting our model to the data, and then we evaluate performance by making predictions on the features of our test data and comparing the predictions to the corresponding target variables for our test data. \n",
    "\n",
    "Let's use an example to walk through this. Imagine that our test dataset consists of the 10 observations below:\n",
    "\n",
    "| $x_1$<br>Sepal width| $x_2$<br>Petal width | $y$<br>Iris Species |\n",
    "| ----- | ------ | ---- |\n",
    "| 3.4 | 0.2\t| setosa     |\n",
    "| 2.9 | 1.3\t| versicolor |\n",
    "| 3.2 | 2.3\t| virginica  |\n",
    "| 3   | 2.2\t| virginica  |\n",
    "| 3\t  | 2.3\t| virginica  |\n",
    "| 3.8 | 2\t| virginica  |\n",
    "| 3   | 0.3\t| setosa     |\n",
    "| 3   | 1.5\t| versicolor |\n",
    "| 2.9 | 1.3\t| versicolor |\n",
    "| 3.1 | 0.2\t| setosa     |\n",
    "\n",
    "Now let's say we use the features of these data to make a *prediction* of the target class label for each of these 10 observations. In other words, we use our classification algorithm, $f$ to make a prediction of $y$ that we refer to as $\\hat{y}$. In this case, $\\hat{y}$ is based on our two features of sepal width ($x_1$) and petal width ($x_2$), such that $\\hat{y} = f(x_1, x_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a column to this table with each of our predictions from our classification algorithm\n",
    "\n",
    "| $x_1$<br>Sepal width| $x_2$<br>Petal width | $y$<br>Iris Species | $\\hat{y}$<br>Iris Species **prediction**|\n",
    "| ----- | ------ | ---- | ---- |\n",
    "| 3.4 | 0.2\t| setosa     | setosa     |\n",
    "| 2.9 | 1.3\t| versicolor | versicolor |\n",
    "| 3.2 | 2.3\t| virginica  | virginica  |\n",
    "| 3   | 2.2\t| **virginica**  | **setosa**     |\n",
    "| 3\t  | 2.3\t| **virginica**  | **setosa**     |\n",
    "| 3.8 | 2\t| virginica  | virginica  |\n",
    "| 3   | 0.3\t| setosa     | setosa     |\n",
    "| 3   | 1.5\t| versicolor | versicolor |\n",
    "| 2.9 | 1.3\t| **versicolor** | **virginica**  |\n",
    "| 3.1 | 0.2\t| setosa     | setosa     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our predictions ($\\hat{y}$) generally match the true test data target variable values ($y$), there are three discrepancies in bold where the prediction did not match the target variable value. That means that 7 out of the 10 predictions were correct. Another way of saying this is that the classification algorithm was correct for 7/10 of the values. In other words, it was 70% accurate on the test data set. Overall accuracy is defined as the fraction of all observations that are correctly classified. We generally seek to create predictive algorithms that are as accurate as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's your turn - write a function that computes the accuracy of predictions when you input the target variable values ($y$) and the predictions ($\\hat{y}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [\"setosa\", \"versicolor\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"setosa\", \"versicolor\", \"versicolor\", \"setosa\"]\n",
    "y_hat = [\"setosa\", \"versicolor\", \"virginica\", \"setosa\", \"setosa\", \"virginica\", \"setosa\", \"versicolor\", \"verginica\", \"setosa\"]\n",
    "\n",
    "# Compute classification accuracy\n",
    "def accuracy(y,y_hat):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always good to test your code - make sure that the result produced is 0.7. Try this before moving on to view the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.array([\"setosa\", \"versicolor\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"setosa\", \"versicolor\", \"versicolor\", \"setosa\"])\n",
    "y_hat = np.array([\"setosa\", \"versicolor\", \"virginica\", \"setosa\", \"setosa\", \"virginica\", \"setosa\", \"versicolor\", \"verginica\", \"setosa\"])\n",
    "\n",
    "# Metric of overall classification accuracy\n",
    "#  both y and y_hat should be numpy arrays\n",
    "def accuracy(y,y_hat):\n",
    "    nvalues = len(y)\n",
    "    accuracy = sum(y == y_hat) / nvalues\n",
    "    return accuracy\n",
    "\n",
    "accuracy(y,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function to evaluate our classification algorithm going forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
