{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LLMs Well\n",
    "\n",
    "We've previously discussed many of the [perils of bring LLMs into your workflow](llms.ipynb) when you are still learning to program. To recap:\n",
    "\n",
    "- LLMs are very good at basic programming. As a result, they can do many of the assignments we are asking you to do. \n",
    "- *BUT* LLMs are not nearly as good at the kind of work you will be doing professionally. At the professional level, LLMs require supervision, and you can only provide that supervision if you understand programming principles well enough to follow along. And you can't learn programming principles without doing those early programming exercises yourself.\n",
    "\n",
    "In other words, we're asking you to do things that LLMs *can* do now on your own so you can develop the skills required to do the things that LLMs *can't* do.\n",
    "\n",
    "But you're now a little further into your education, and so it's time to discuss healthy habits for LLM integration.\n",
    "\n",
    "## Be Deliberate\n",
    "\n",
    "My first rule for using LLMs is to always be deliberate about when you bring LLMs into the conversation. \n",
    "\n",
    "Tools that offer code suggestions as you type (as shadow code) are my absolute least favorite form of LLMs because there's no way for you to avoid having the LLM hijack your thought process. \"Sure,\" you say, \"I don't have to accept the LLM suggestions.\" And that's true. But even if you don't, it is almost impossible to ignore them entirely, and as soon as you engage with them in even a cursory manner, they start to influence how you think about a problem. \n",
    "\n",
    "Instead, I am a big advocate for chat-based LLM interfaces. As we'll discuss below, I use the Github Copilot chat interface when I use an LLM for coding, and I've attached it to a keyboard shortcut so that I don't have to leave it open to feel like it's accessible. Instead, it's almost never in view, and when I decide it would be helpful I invoke it, use it, and then close it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't Start with the LLM â€” Course Materials are Better\n",
    "\n",
    "One thing we faculty see a lot is students turning to LLMs when they hit a problem, and the LLM leading them *way* off track. The answers it give may *work*, but they're convoluted, unnecessarily complicated, or use packages or techniques that have not yet been introduced.\n",
    "\n",
    "Your instructor, your TAs, the materials you were assigned for a class, and your peers will almost always be better resources for you in a reasonably well-designed class because they understand what you have been taught, where you are in your learning journey, and the learning goal of the assignment you're working on. None of that is available to the LLMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Never Use Something You Don't Understand\n",
    "\n",
    "A closely related point is that you should *never* copy-paste code from an LLM you don't understand. LLMs are great tools for helping you find your way sometimes, but if you don't fully understand an LLMs suggestions, you should do more research before putting it into your code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Context is King\n",
    "\n",
    "Perhaps the most important factor in whether an LLM will be helpful to you is to how much access it has to the context in which you are working. Context, in other words, is King. \n",
    "\n",
    "In practice, that means you should really avoid using a chat app running in your browser as your main LLM interface. Instead, you want to use an interface that allows the LLM to see the files you are working with.\n",
    "\n",
    "The most straightforward way to give an LLM visibility into your work is to use Github Copilot Chat in VS Code. Using Copilot Chat means that the LLM will see all the files you have open or which are visible in your folders tab automatically. Moreover, it is model-agnostic, by which I mean it lets you pick from a range of different LLM models to work on the backend. (You can get Copilot Pro free with a [Student Github account](https://github.com/education/students), which gives you access to more models than you get for free).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask for Help Understanding\n",
    "\n",
    "\"Can you explain why...\" or \"Explain why I'm getting this error...\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
