# Linear Regression in Python

Linear regression — also sometimes referred to as multiple regression, least squares regression, and Ordinary Least Squares (OLS), among many other names — is the first data science tool most students encounter, and it is still one of the most used even in a world of increasingly sophisticated tools.

This week's readings will discuss how linear regression fits into the Python data science ecosystem. First, though, we need to acknowledge that linear regression does not fit naturally into the framework we have developed for this course (or for our *Python Programming for Data Science* specialization more generally). Up until now, we have assumed that students in these courses are familiar with a few basic statistics concepts like means, medians, variance and standard deviation, but we have otherwise limited our focus to the implementation side of data science. That's because we believe to be a good data scientist, one must have good programming skills, a good understanding of the statistics that underlie the tools data scientists use and have familiarity with the substantive domain to which those tools are being applied. There are intro data science courses that try and provide an introduction to all three facets of the discipline, but the depth of the material they are able to cover is limited by the breadth they are trying to achieve. In this course, by contrast, we've chosen to focus on one of those facets — programming for data science — and really dive in.

At the same time, we know some people coming to this course will have experience with more advanced statistics or machine learning methods. They may have taken an introductory statistics courses that covered topics like linear regression. They may also be highly experienced social scientists or statisticians seeking to improve their program abilities or move from a programming language like R or Stata to Python. And students in that position would probably feel understandably frustrated if their Python Programming for Data Science specialization never told them anything about the major modelling libraries and how they work.

With that in mind, the readings for this week are a little unusual in structure.

In the next reading — *Linear Regression: A Brief Introduction* — we provide an intuitive introduction to linear regression that assumes only basic statistical knowledge. This reading certainly is not a substitute for a good course on linear regression, but it should provide readers with enough of a sense of the how linear regressions work and what they seek to accomplish to understand the readings that follow. In addition, we will offer recommendations for other, more in-depth, courses on linear regression for students interested in learning more. *If you are already familiar with linear regression,* please feel free to skip this next reading.

In the readings that follow *Linear Regression: A Brief Introduction*, we will then turn to how to implement linear regressions in Python with a particular emphasis on two libraries: [statsmodels](http://statsmodels.org) and [scikit-learn](http://scikit-learn.org).

**If you are a student who is seeing linear regression for the first time:** your goal will not to understand everything in these readings, but rather to get a sense of how linear regression works in Python. There are plenty of sections you will be able to follow in their entirety, but from time to time we will discuss how to get Python to do something that goes beyond what we cover in the *Linear Regression: A Brief Introduction* reading, but which students with experience in linear regression will want to know how to do. We will do our best to be explicit when we are doing this, but in case we forget, just be aware that there will be things we don't expect all learners to understand. Graded quizzes will be limited to the material that we feel *all* learners can (and should!) follow.

**If you are a student who has more experience with linear regression:** we are very confident you will find value in everything that follows save the *Linear Regression: A Brief Introduction* reading. This value will come both directly (you will learn how to do many things you want to do) and indirectly (we will tell you where to go to learn more about how to fit that *one model* you just can't live without).

**If you're a Bayesian:** we won't be covering Bayesian modeling in this course, but worry not — Python has some really terrific Bayesian modeling tools. [PyMC](https://www.pymc.io/welcome.html) is a mature, fully developed, Python-native probabilistic programming language. And if you're more of a Bayesian lightweight and are used to tools like `rstanarm` from the R world, you can jump to [Bambi](https://bambinos.github.io/bambi/), a higher-level modeling library built on top of PyMC.
