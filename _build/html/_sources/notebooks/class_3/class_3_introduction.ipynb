{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming with data\n",
    "\n",
    "So far in this specialization, we have focused on two key programming skillsets: (1) fundamentals of Python programming and software engineering - thinking like a programmer and understanding best practices for creating bug-free code and (2) tools for numerical programming and computation (in particular `numpy`) and how to use those programming tools to perform complex operations. What we will explore in this course, is how to work with data programmatically: loading in data, checking data for potential issues or errors, and tools for efficiently analyzing/querying data (in particular `pandas`). In particular, we focus on the most common type of data with which most data scientists will work: tabular data. We have devoted an entire course to programming tools for working with data because it is a foundational skill for an aspiring data scientist as data preparation often represents a significant (if not the *most* significant) share of time for data science projects. A clear understanding of the programming tools can help you to spend less time struggling to ingest or prepare your data, and more time actually learning from the data.\n",
    "\n",
    "## Structure of the course\n",
    "\n",
    "This course is divided into four weeks. In week 1, you'll learn about file IO: how to read and write data. You'll learn how Python can directly read different file types and how to handle errors that occur in that process correctly. In week two, we will explore a package for handling data that abstracts some of the lower level file IO issues to make it easier to read, write, and analyze data: `pandas`. In this second week, you'll learn two key components of `pandas`: the Series and the DataFrame, which are powerful tools for asking questions about our data. Week 3 dives deeper into the productive use of `pandas` for working with data, including how to quickly and easily read from and write to files, how to check for issues with your loaded data, and strategies for cleaning the data. In week 4, we bring it all together, literally, by talking about how to combine multiple datasets through merging and grouping data, as well as ways to filter/search a dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9e56a7b23b1fac2eea1a993b805ed5c611aea1439c1f46315b23590ab6d3ba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
