{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyArrow: An Alternative to Numpy as Pandas Backend\n",
    "\n",
    "As discussed in our previous readings, by default pandas data structures are basically numpy arrays wrapped up with some additional functionality. Indeed, we can see this by calling the `.values` property on our pandas data structures:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [3.14, 2.718, 1.41421]})\n",
    "type(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting in `pandas 2.0`, however, it is possible to change how pandas data is stored in the background — instead of storing data in numpy arrays, pandas can now also store data in Arrow arrays using the `pyarrow` library.\n",
    "\n",
    "## Why A New Backend?\n",
    "\n",
    "Arrow arrays are functionally very similar to numpy arrays, but with a few differences behind the scenes.\n",
    "\n",
    "The first — and as I understand it, the motivation for the creation of Arrow — is that it's designed to be more interoperable with other programming languages. Basically, the Arrow array format was invented because different programming languages organize the 1s and 0s underlying arrays differently in computer memory. As a result, moving arrays between programming languages—like Python, R, or Julia—requires reformatting data. With Arrow arrays, by contrast, one can move data between programming languages without computational overhead. In other words, it's a way of storing arrays in memory that is *programming language agnostic*. \n",
    "\n",
    "And the dream is that by reducing the overhead to moving between programming languages, fights over which language is \"best\" would come to an end, and people would move between R, Python, Julia, and who knows what else effortlessly (I'll admit I'm *deeply* dubious that will ever happen, but one can dream, right?!).\n",
    "\n",
    "Arrow was created by the Apache Software Foundation (it's sometimes called Apache Arrow), and is the in-memory analogue of their `parquet` file format for storing arrays to disk, something we'll talk about in a future reading.\n",
    "\n",
    "### String Performance\n",
    "\n",
    "But honestly, that's not the main reason that pandas users are fond of Arrow — the *main* reason is that Arrow arrays have a `string` datatype that is *far* faster and more memory efficient than the current way strings are stored in pandas (as `object` dtypes). \n",
    "\n",
    "Indeed, this performance difference is so great that starting in `pandas 3.0`, all strings will be silently stored as PyArrow strings by default (though with all the syntax you've come to know and love from numpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PyArrow\n",
    "\n",
    "The uses of PyArrow for pandas are evolving quickly, so if you're really interested you may simply wish to go read the [pandas docs](https://pandas.pydata.org/docs/user_guide/pyarrow.html) on the topic.\n",
    "\n",
    "But to give you a quick sense of things, here's an example of how you can convert a numpy-backed pandas DataFrame into an Arrow-backed DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   a       3 non-null      int64  \n",
      " 1   b       3 non-null      float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 180.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [3.14, 2.718, 1.41421]})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      int64\n",
       "b    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.71800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.41421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a        b\n",
       "0  1  3.14000\n",
       "1  2  2.71800\n",
       "2  3  1.41421"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_pyarrow_backend = df.convert_dtypes(dtype_backend=\"pyarrow\")\n",
    "df_w_pyarrow_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     int64[pyarrow]\n",
       "b    double[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_pyarrow_backend.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you want to have pandas read data directly into Arrow arrays when using a `pd.read_...` function, simply add the keyword argument `dtype_backend=\"pyarrow\"` (e.g., like `df = pd.read_csv(\"path_to_file.csv\", dtype_backend=\"pyarrow\")`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is This Something To Worry About Now?\n",
    "\n",
    "Meh, probably not.\n",
    "\n",
    "The one situation where I might use pyarrow now is if I were working with LOTS of text data. In that case, there are substantial performance returns to using pyarrow. \n",
    "\n",
    "But I probably wouldn't convert *all* my data into Arrow arrays. As noted above, starting in `pandas 3.0`, string data will automagically use Arrow string dtypes in the background in a way that doesn't change how anything works from the perspective of the user. But while this doesn't become the *default* behavior till `pandas 3.0`, it can be enabled early starting with `pandas 2.1` using the option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.future.infer_string = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a                    int64\n",
       "b                  float64\n",
       "c    string[pyarrow_numpy]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"a\": [1, 2, 3], \"b\": [3.14, 2.718, 1.41421], \"c\": [\"hello\", \"world\", \"hamburger\"]}\n",
    ")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we did want to make sure to tell you about this so you won't be surprised if you read about it on the internet!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}