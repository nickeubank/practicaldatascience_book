{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LLMs Well\n",
    "\n",
    "We've previously discussed many of the [perils of bring LLMs into your workflow](llms.ipynb) when you are still learning to program. To recap:\n",
    "\n",
    "- LLMs are very good at basic programming. As a result, they can do many of the assignments we are asking you to do. \n",
    "- **BUT**: LLMs are *not* as good at the kind of work you will be doing professionally. At the professional level, LLMs require supervision, and you can only provide that supervision if you understand programming principles well enough to follow along. And you can't learn programming principles without doing those early programming exercises yourself.\n",
    "\n",
    "In other words, you have to know how to do the things that LLMs *can* do now so you can develop the skills required to do the things that LLMs *can't* do down the road.\n",
    "\n",
    "But you're now a little further into your education, and so it's time to discuss healthy habits for LLM integration. And with that in mind, my Do's and Don'ts for LLM usage (when writing code):\n",
    "\n",
    "\n",
    "\n",
    "1. ***Do* be deliberate about AI use:** as with so many technologies (looking at you social media), it's important to also be sure YOU are in control of when and how AI is influencing your thinking.\n",
    "\n",
    "For that reason, I much prefer chat-based LLM coding interfaces. As we'll discuss below, I use the Github Copilot chat interface when I use an LLM for coding. This is a chat window that opens in VS Code *beside* my code to offer suggestions. The tool can directly modify my code if I ask it to, but it only acts if I ask it to act, and I can easily put it away. \n",
    "\n",
    "![copilot chat window](images/copilot_chat_window.png)\n",
    "\n",
    "I've attached it to a keyboard shortcut so that I don't have to leave it open to feel like it's accessible. Instead, it's almost never in view, and when I decide it would be helpful I invoke it, use it, and then close it.\n",
    "\n",
    "Tools that offer code suggestions as you type (as greyed code suggestions), by contrast, are my absolute least favorite form of LLMs because there's no way for you to avoid having the LLM hijack your thought process. \"Sure,\" you say, \"I don't have to accept the LLM suggestions.\" And that's true. But even if you don't accept an LLM recommendation, it is almost impossible to ignore text that pops up right in front of your cursor entirely, and as soon as you engage with that text, it will start to influence how you think about a problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ***Don't* Start with the LLM â€” Course Materials are Better:**\n",
    "\n",
    "Your instructor, your TAs, the materials you were assigned for a class, and your peers will almost always be better resources for you than LLMs in a reasonably well-designed class. That's because they understand what you have been taught, where you are in your learning journey, and the learning goal of the assignment you're working on. None of that information is available to an LLMs. \n",
    "\n",
    "As a result, we faculty see countless examples of students turning to LLMs when they hit a problem, only to have the LLM leading them *way* off track. The answers LLMs give students may *work*, but they're often convoluted, unnecessarily complicated, and/or use packages or techniques that have not yet been introduced. And the consequence is students *may* manage to solve the problem in front of them, but the often won't learn what they're supposed to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ***Do* Use AI for things that are:**\n",
    "\n",
    " - (1) labor intensive to do, \n",
    " - (2) you *could* do yourself, but which are \n",
    " - (3) easy to verify have been done correctly.\n",
    "\n",
    "Tasks that meet these three criteria are what I think of as being *right* in the wheelhouse of AI. Using AI for things that are easy to do just dulls your skills, while using it for things that are annoying and time-consuming makes you more efficient. Moreover, asking for help with things you could do yourself (maybe with a little google help) means you're asking for help with something you know even to check over. And finally, tasks that are labor-intensive to do but easily to validate mean you don't have to overly rely on the AI to do something correctly.\n",
    "\n",
    "Examples of this type of task include:\n",
    "\n",
    "- Making refinements to matplotlib figures: matplotlib has a thousand and one different methods and ways to tweak plots, so trying to find the exact right one to change a plot in a certain way (e.g., trying to \"add text rotated ninety degrees between the figure and the legend\") can take you FOREVER. AI allows you to say what you want in plain English and leave the challenge of figuring out the exact incantation to the LLM. And of course, you can immediately look at the result to see if it worked! Of course, AI won't always get things exactly right, so understanding at a conceptual level how a library like matplotlib works will allow you to tweak the solution provided by the LLM.\n",
    "- \n",
    "\n",
    "\n",
    "If you're asking AI to help with a task you *could* do, that also implies it's a task that you can also supervise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. *Do* Use AI for things that you could do yourself, but which are kinda annoying to do.\n",
    "\n",
    "A closely related point is that you should *never* copy-paste code from an LLM you don't understand. LLMs are great tools for helping you find your way sometimes, but if you don't fully understand an LLMs suggestions, you should do more research before putting it into your code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Context is King\n",
    "\n",
    "Perhaps the most important factor in whether an LLM will be helpful to you is to how much access it has to the context in which you are working. Context, in other words, is King. \n",
    "\n",
    "In practice, that means you should really avoid using a chat app running in your browser as your main LLM interface. Instead, you want to use an interface that allows the LLM to see the files you are working with.\n",
    "\n",
    "The most straightforward way to give an LLM visibility into your work is to use Github Copilot Chat in VS Code. Using Copilot Chat means that the LLM will see all the files you have open or which are visible in your folders tab automatically. Moreover, it is model-agnostic, by which I mean it lets you pick from a range of different LLM models to work on the backend. (You can get Copilot Pro free with a [Student Github account](https://github.com/education/students), which gives you access to more models than you get for free).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask for Help Understanding\n",
    "\n",
    "\"Can you explain why...\" or \"Explain why I'm getting this error...\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}