{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Variables, Indicator Variables and Linear Regression\n",
    "\n",
    "An important concept in working with linear regressions is how to handle *categorical data*.\n",
    "\n",
    "In our last reading on linear regression, we limited our discussion to how it works with numeric variables, like prices, square footage, or condition ratings. In each case, these have been examples of *cardinal* variables — variables in which constant changes in the value of the variable have the same significance, regardless of the starting and end points. Moving from 100 to 101 square feet is the same as moving from 1,000 to 1,001 square feet, for example, and moving from `condition=1` to `condition=2` is *supposed* to have the same meaning as moving from `condition=4` to `condition=5`.\n",
    "\n",
    "But data science is full of factors that are not cardinal variables we may wish to incorporate into our analysis, such as a patient's race, gender, and education level, or the neighborhood in which a property is located. \n",
    "\n",
    "We call these variables *categorical* variables because each distinct value of the variable — like each potential racial classification for a patient — is a distinct category without a clear relationship to other categories. Categorical variables are often stored as strings (`\"Male\"` and `\"Female\"` for gender, for example), but they can also be stored as numeric datatypes (neighborhoods in our housing data are represented in integer zip codes). But even when they are represented as numbers (like zip codes), those numbers are just labels for categories — there's no sense in which we'd expect that moving from zip code `90210` to `90211` would have the same effect on the price of a home as moving from `11110` to `11111`, as with cardinal variables.\n",
    "\n",
    "Thankfully, with the use of *indicator variables* (also often called \"dummy variables\"), categorical variables are relatively easy to accommodate within linear regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Binary Categorical Variables\n",
    "\n",
    "To illustrate how indicator variables operate, let's start by considering a categorical variable in our housing dataset that only takes on two values — `waterfront`. When a property is located along a body of water, the value of `waterfront` is `1`, and when it is not, the value of `waterfront` is `0`. \n",
    "\n",
    "This type of binary categorical variable is not uncommon. Gender, for example, is often stored in datasets as a binary indicator variable (potentially called `female`) that takes on a value of `1` if the respondent identifies as a woman and `0` if they identify as male (obviously, society is increasingly coming to acknowledge that this simple dichotomous classification scheme is simplistic, and so you will see more categories for gender in newer datasets, but this two-category coding is still very common). Similarly, in experiments, observations are in either the treatment group (`treatment` is `1`) or the control group (`treatment` is `0`).\n",
    "\n",
    "Moreover, this coding scheme is easy to create in situations where the dataset stores values as a string. Suppose, for example, you have a dataset in which `gender` is coded with the strings `\"male\"` and `\"female\"`. You can easily make this a 0-1 variable with:\n",
    "\n",
    "```python\n",
    "df[\"female\"] = (df[\"gender\"] == \"female\").astype(\"int\")\n",
    "```\n",
    "\n",
    "Variables that take on only the values of `0` or `1` \"indicator variables\" because they *indicate* membership in a specific group. \n",
    "\n",
    "## Interpreting Binary Indicator Variables in Regression\n",
    "\n",
    "Once your binary variable has been converted to a `0-1` indicator variable, we can add it to our regression just like any other variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.071</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.071</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1650.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 20 Jul 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:44:13</td>     <th>  Log-Likelihood:    </th> <td>-3.0681e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21613</td>      <th>  AIC:               </th>  <td>6.136e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21611</td>      <th>  BIC:               </th>  <td>6.136e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td> 5.316e+05</td> <td> 2416.194</td> <td>  220.000</td> <td> 0.000</td> <td> 5.27e+05</td> <td> 5.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th> <td>  1.13e+06</td> <td> 2.78e+04</td> <td>   40.626</td> <td> 0.000</td> <td> 1.08e+06</td> <td> 1.18e+06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17750.357</td> <th>  Durbin-Watson:     </th>  <td>   1.962</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>924317.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.605</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>34.215</td>   <th>  Cond. No.          </th>  <td>    11.6</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &      0.071   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.071   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      1650.   \\\\\n",
       "\\textbf{Date:}             & Sat, 20 Jul 2024 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n",
       "\\textbf{Time:}             &     18:44:13     & \\textbf{  Log-Likelihood:    } & -3.0681e+05  \\\\\n",
       "\\textbf{No. Observations:} &       21613      & \\textbf{  AIC:               } &  6.136e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &       21611      & \\textbf{  BIC:               } &  6.136e+05   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &              \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}  &    5.316e+05  &     2416.194     &   220.000  &         0.000        &     5.27e+05    &     5.36e+05     \\\\\n",
       "\\textbf{waterfront} &     1.13e+06  &     2.78e+04     &    40.626  &         0.000        &     1.08e+06    &     1.18e+06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 17750.357 & \\textbf{  Durbin-Watson:     } &     1.962   \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 924317.834  \\\\\n",
       "\\textbf{Skew:}          &    3.605  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &   34.215  & \\textbf{  Cond. No.          } &      11.6   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.071\n",
       "Model:                            OLS   Adj. R-squared:                  0.071\n",
       "Method:                 Least Squares   F-statistic:                     1650.\n",
       "Date:                Sat, 20 Jul 2024   Prob (F-statistic):               0.00\n",
       "Time:                        18:44:13   Log-Likelihood:            -3.0681e+05\n",
       "No. Observations:               21613   AIC:                         6.136e+05\n",
       "Df Residuals:                   21611   BIC:                         6.136e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   5.316e+05   2416.194    220.000      0.000    5.27e+05    5.36e+05\n",
       "waterfront   1.13e+06   2.78e+04     40.626      0.000    1.08e+06    1.18e+06\n",
       "==============================================================================\n",
       "Omnibus:                    17750.357   Durbin-Watson:                   1.962\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           924317.834\n",
       "Skew:                           3.605   Prob(JB):                         0.00\n",
       "Kurtosis:                      34.215   Cond. No.                         11.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "\n",
    "home_prices = pd.read_csv(\"data/kc_house_data.csv\")\n",
    "price_reg = smf.ols(\"price ~ waterfront\", data=home_prices).fit()\n",
    "price_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then interpret the coefficient associated with our indicator variable — in this case, about 1,130,000 — as the average difference between houses when the variable equals `1` (in other words, when a house is on the waterfront) and when the variable equals `0`. In fact, a regression like this that only includes one binary indicator variable is exactly equivalent to a t-test, if you know what those are.\n",
    "\n",
    "If we add other variables to the regression, then the interpretation is still basically the same: the coefficient is the average difference between observations where the indicator is `1` and the reference group (observations where the indicator is `0`). The only difference is that when other variables are included, we would say that this is the average difference between houses on the water front and those not on the water front *accounting for the other variables in the regression*. \n",
    "\n",
    "For example, suppose we knew that homes on the water front tended to be much bigger than homes that are not on the water front in this city. Because of this, when we compare all water front homes to non-water front homes, part of the difference we're measuring isn't actually the price increase caused by being on the water front, per se, but rather the simple fact that water front homes tend to be bigger, and bigger homes cost more.\n",
    "\n",
    "To address this, we could include square footage in the regression. Then we can interpret the coefficient on `waterfront` as the average difference in home prices between houses on the water front and houses not on the water front *accounting for differences in square footage* (or, said differently, the average difference in prices for homes of the same size on and off the water front). \n",
    "\n",
    "And indeed, because most houses on the water front tend to be bigger than houses not on the water front, when we control for square footage by including it in the regression, the coefficient on `waterfront` falls from `1,130,000` to about `830,000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.531</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.531</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.222e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 20 Jul 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:44:13</td>     <th>  Log-Likelihood:    </th> <td>-2.9943e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21613</td>      <th>  AIC:               </th>  <td>5.989e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21610</td>      <th>  BIC:               </th>  <td>5.989e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>-3.296e+04</td> <td> 4242.971</td> <td>   -7.768</td> <td> 0.000</td> <td>-4.13e+04</td> <td>-2.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>  <td>   8.3e+05</td> <td> 1.99e+04</td> <td>   41.745</td> <td> 0.000</td> <td> 7.91e+05</td> <td> 8.69e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th> <td>  272.5066</td> <td>    1.873</td> <td>  145.499</td> <td> 0.000</td> <td>  268.836</td> <td>  276.178</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13423.699</td> <th>  Durbin-Watson:     </th>  <td>   1.980</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>444123.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.462</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>24.655</td>   <th>  Cond. No.          </th>  <td>2.64e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.64e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &      0.531   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.531   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &  1.222e+04   \\\\\n",
       "\\textbf{Date:}             & Sat, 20 Jul 2024 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n",
       "\\textbf{Time:}             &     18:44:13     & \\textbf{  Log-Likelihood:    } & -2.9943e+05  \\\\\n",
       "\\textbf{No. Observations:} &       21613      & \\textbf{  AIC:               } &  5.989e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &       21610      & \\textbf{  BIC:               } &  5.989e+05   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &              \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}    &   -3.296e+04  &     4242.971     &    -7.768  &         0.000        &    -4.13e+04    &    -2.46e+04     \\\\\n",
       "\\textbf{waterfront}   &      8.3e+05  &     1.99e+04     &    41.745  &         0.000        &     7.91e+05    &     8.69e+05     \\\\\n",
       "\\textbf{sqft\\_living} &     272.5066  &        1.873     &   145.499  &         0.000        &      268.836    &      276.178     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 13423.699 & \\textbf{  Durbin-Watson:     } &     1.980   \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 444123.936  \\\\\n",
       "\\textbf{Skew:}          &    2.462  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &   24.655  & \\textbf{  Cond. No.          } &  2.64e+04   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.64e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.531\n",
       "Model:                            OLS   Adj. R-squared:                  0.531\n",
       "Method:                 Least Squares   F-statistic:                 1.222e+04\n",
       "Date:                Sat, 20 Jul 2024   Prob (F-statistic):               0.00\n",
       "Time:                        18:44:13   Log-Likelihood:            -2.9943e+05\n",
       "No. Observations:               21613   AIC:                         5.989e+05\n",
       "Df Residuals:                   21610   BIC:                         5.989e+05\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept   -3.296e+04   4242.971     -7.768      0.000   -4.13e+04   -2.46e+04\n",
       "waterfront     8.3e+05   1.99e+04     41.745      0.000    7.91e+05    8.69e+05\n",
       "sqft_living   272.5066      1.873    145.499      0.000     268.836     276.178\n",
       "==============================================================================\n",
       "Omnibus:                    13423.699   Durbin-Watson:                   1.980\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           444123.936\n",
       "Skew:                           2.462   Prob(JB):                         0.00\n",
       "Kurtosis:                      24.655   Cond. No.                     2.64e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.64e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_reg = smf.ols(\"price ~ waterfront + sqft_living\", data=home_prices).fit()\n",
    "price_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator Variables, Categorical Variables, and One-Hot Encoding\n",
    "\n",
    "Of course, not all categorical variables are binary — education, race, and neighborhood are all examples of factors we might want to include in a data science analysis that are categorical and which have far more than two possible values. \n",
    "\n",
    "We can account for these types of categorical variables using *one-hot encoding*. The idea of one-hot encoding is to create a series of 0-1 indicator variables, one for each unique value of the variable.\n",
    "\n",
    "To illustrate, suppose you are analyzing data on salaries, and your data includes a variable for education. The variable has values `1`, `2`, `3`, and `4`. The documentation says the variable reports the highest level of education completed by the respondent and that values of `1` are for respondents with \"less than a high school diploma,\" `2` is for respondents who graduated high school, `3` is for respondents who graduated college, and `4` is for respondents with a graduate degree.\n",
    "\n",
    "Clearly, there's no reason to think that going from not having a high school diploma to graduating high school (moving from `1` to `2`) would have the same effect on earnings as moving from being a high school graduate (`2`) to becoming a college graduate (`3`). So even though this variable is stored as an `int` datatype, we wouldn't want to treat it as a normal, cardinal variable. \n",
    "\n",
    "Instead, we can create an 0-1 indicator variable for \"does respondent have less than a high school diploma,\" another variable for \"is respondent's highest educational level a high school diploma,\" one for \"is respondent's highest educational level a college degree,\" and finally one for \"is respondent's highest educational level a graduate degree.\" Essentially, the data would look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![One-hot-encoding](img/one-hot-encoding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   education\n",
       "0          1\n",
       "1          2\n",
       "2          3\n",
       "3          2\n",
       "4          1\n",
       "5          4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries = pd.DataFrame({\"education\": [1, 2, 3, 2, 1, 4]})\n",
    "salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>highschool</th>\n",
       "      <th>college</th>\n",
       "      <th>graduate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   education  highschool  college  graduate\n",
       "0          1           0        0         0\n",
       "1          2           1        0         0\n",
       "2          3           0        1         0\n",
       "3          2           1        0         0\n",
       "4          1           0        0         0\n",
       "5          4           0        0         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encodings = pd.get_dummies(salaries[\"education\"], drop_first=True).astype(\"int\")\n",
    "one_hot_encodings = one_hot_encodings.rename(\n",
    "    columns={2: \"highschool\", 3: \"college\", 4: \"graduate\"}\n",
    ")\n",
    "pd.concat([salaries, one_hot_encodings], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you'll see, we didn't actually create an indicator for *every* value — we created an indicator for every value but 1. `education` takes on 4 values, but we have only created 3 indicator variables. That's because one category is implied when the other three indicator variables are equal to 0. In this case, when `education` is equal to `1`, the three indicator variables all take on a value of `0`. This omitted category (here, having less than a high school diploma) is  referred to as the \"reference category.\"\n",
    "\n",
    "Now that we've converted this variable into indicators, we can put them into a regression and interpret the coefficient on each as the average difference between the group indicated by the specific indicator and the reference category (the condition for which all the indicator variables in the regression are equal to 0).\n",
    "\n",
    "To illustrate, let's consider the number of bedrooms in a house. While we could think of the number of bathrooms as a normal cardinal variable, in reality there aren't many people deciding between a 1 bedroom and a 2 or more bedroom house, so they market for 1 bedroom homes and homes with more bedrooms are basically entirely different markets. \n",
    "\n",
    "These dataset also has some homes with zero bedrooms (?!), and some with a ton of bedrooms (up to 33!), so let's also subset for sane homes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sane_home_prices = home_prices[\n",
    "    (0 < home_prices[\"bedrooms\"]) & (home_prices[\"bedrooms\"] <= 6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.104</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.104</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   500.1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 20 Jul 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:44:13</td>     <th>  Log-Likelihood:    </th> <td>-3.0523e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21538</td>      <th>  AIC:               </th>  <td>6.105e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21532</td>      <th>  BIC:               </th>  <td>6.105e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td> 3.176e+05</td> <td> 2.45e+04</td> <td>   12.969</td> <td> 0.000</td> <td>  2.7e+05</td> <td> 3.66e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedrooms)[T.2]</th> <td> 8.373e+04</td> <td> 2.54e+04</td> <td>    3.302</td> <td> 0.001</td> <td>  3.4e+04</td> <td> 1.33e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedrooms)[T.3]</th> <td> 1.486e+05</td> <td> 2.47e+04</td> <td>    6.006</td> <td> 0.000</td> <td>    1e+05</td> <td> 1.97e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedrooms)[T.4]</th> <td> 3.178e+05</td> <td> 2.48e+04</td> <td>   12.791</td> <td> 0.000</td> <td> 2.69e+05</td> <td> 3.66e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedrooms)[T.5]</th> <td>  4.69e+05</td> <td>  2.6e+04</td> <td>   18.058</td> <td> 0.000</td> <td> 4.18e+05</td> <td>  5.2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedrooms)[T.6]</th> <td> 5.079e+05</td> <td> 3.22e+04</td> <td>   15.759</td> <td> 0.000</td> <td> 4.45e+05</td> <td> 5.71e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19014.949</td> <th>  Durbin-Watson:     </th>  <td>   1.958</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1234316.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.973</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>39.225</td>   <th>  Cond. No.          </th>  <td>    30.0</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &      0.104   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.104   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      500.1   \\\\\n",
       "\\textbf{Date:}             & Sat, 20 Jul 2024 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n",
       "\\textbf{Time:}             &     18:44:13     & \\textbf{  Log-Likelihood:    } & -3.0523e+05  \\\\\n",
       "\\textbf{No. Observations:} &       21538      & \\textbf{  AIC:               } &  6.105e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &       21532      & \\textbf{  BIC:               } &  6.105e+05   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &              \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}        &    3.176e+05  &     2.45e+04     &    12.969  &         0.000        &      2.7e+05    &     3.66e+05     \\\\\n",
       "\\textbf{C(bedrooms)[T.2]} &    8.373e+04  &     2.54e+04     &     3.302  &         0.001        &      3.4e+04    &     1.33e+05     \\\\\n",
       "\\textbf{C(bedrooms)[T.3]} &    1.486e+05  &     2.47e+04     &     6.006  &         0.000        &        1e+05    &     1.97e+05     \\\\\n",
       "\\textbf{C(bedrooms)[T.4]} &    3.178e+05  &     2.48e+04     &    12.791  &         0.000        &     2.69e+05    &     3.66e+05     \\\\\n",
       "\\textbf{C(bedrooms)[T.5]} &     4.69e+05  &      2.6e+04     &    18.058  &         0.000        &     4.18e+05    &      5.2e+05     \\\\\n",
       "\\textbf{C(bedrooms)[T.6]} &    5.079e+05  &     3.22e+04     &    15.759  &         0.000        &     4.45e+05    &     5.71e+05     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 19014.949 & \\textbf{  Durbin-Watson:     } &      1.958   \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 1234316.627  \\\\\n",
       "\\textbf{Skew:}          &    3.973  & \\textbf{  Prob(JB):          } &       0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &   39.225  & \\textbf{  Cond. No.          } &       30.0   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.104\n",
       "Model:                            OLS   Adj. R-squared:                  0.104\n",
       "Method:                 Least Squares   F-statistic:                     500.1\n",
       "Date:                Sat, 20 Jul 2024   Prob (F-statistic):               0.00\n",
       "Time:                        18:44:13   Log-Likelihood:            -3.0523e+05\n",
       "No. Observations:               21538   AIC:                         6.105e+05\n",
       "Df Residuals:                   21532   BIC:                         6.105e+05\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept         3.176e+05   2.45e+04     12.969      0.000     2.7e+05    3.66e+05\n",
       "C(bedrooms)[T.2]  8.373e+04   2.54e+04      3.302      0.001     3.4e+04    1.33e+05\n",
       "C(bedrooms)[T.3]  1.486e+05   2.47e+04      6.006      0.000       1e+05    1.97e+05\n",
       "C(bedrooms)[T.4]  3.178e+05   2.48e+04     12.791      0.000    2.69e+05    3.66e+05\n",
       "C(bedrooms)[T.5]   4.69e+05    2.6e+04     18.058      0.000    4.18e+05     5.2e+05\n",
       "C(bedrooms)[T.6]  5.079e+05   3.22e+04     15.759      0.000    4.45e+05    5.71e+05\n",
       "==============================================================================\n",
       "Omnibus:                    19014.949   Durbin-Watson:                   1.958\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1234316.627\n",
       "Skew:                           3.973   Prob(JB):                         0.00\n",
       "Kurtosis:                      39.225   Cond. No.                         30.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_reg = smf.ols(\"price ~ C(bedrooms)\", data=sane_home_prices).fit()\n",
    "price_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You will notice that rather than creating indicator variables with the `pd.get_dummies()` function, I just put `C()` around `bedrooms` in the regression — that's a trick we'll discuss in more detail in a future reading.)\n",
    "\n",
    "The way to read this table is that `C(bedrooms)[T.2]` is the coefficient on the indicator for `bedrooms` equalling `2`, `C(bedrooms)[T.3]` is for `bedrooms` equalling `3`, etc. The reference category (the category for which we did not create an indicator variable) is when `bedrooms` was `1`. \n",
    "\n",
    "Because our reference category is one-bedroom homes, the bedroom coefficients all tell us the average difference between a home with [number of homes implied by indicator] and a one-bedroom home. So the coefficient of about `83,730` on `C(bedrooms)[T.2]` means that two bedroom homes are, on average, 83,730 dollars more expensive than single bedroom homes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we want to know the difference in the average price of a two-bedroom home and a *three* bedroom home? That statistic is not immediately present in the table, but can be easily derived by taking the difference of the coefficient on `C(bedrooms)[T.2]` and `C(bedrooms)[T.3]` — since each of these is the difference between a 2 / 3 bedroom house and a 1 bedroom house, when you take the difference, the \"minus the average price of a 1 bedroom house\" cancels out (again, don't worry about the code syntax. We'll cover it in detail later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg difference between a three and two bedroom home is: 64,859 dollars\n"
     ]
    }
   ],
   "source": [
    "diff = price_reg.params[\"C(bedrooms)[T.3]\"] - price_reg.params[\"C(bedrooms)[T.2]\"]\n",
    "print(\n",
    "    f\"The avg difference between a three and two bedroom home is: {diff:,.0f} dollars\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "We've covered a *lot* of material in this reading and the one that preceded it. If you've never seen a linear regression before, there's a good chance you're feeling a little overwhelmed. Don't worry — remember that the goal of these readings is just to give you enough of a sense of how linear regressions work for us to discuss how linear regressions are implemented in Python. These readings are *definitely* not going to teach you all you need to know about linear regression or to even make you feel like you really *get* regression. And that's ok. So long as you can get a lot out of the readings that follow, you're doing great."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}