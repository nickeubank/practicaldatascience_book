{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First steps in coding your own KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start coding your own KNN classifier! Let's begin by reviewing the pseudocode for our KNN classifier:\n",
    "\n",
    "**Model training** is the process of fitting the model to the data to help it to make as accurate of predictions for unlabeled data as possible. In this case, it has one simple step:\n",
    "1. Load and save the training data (features and the outputs we wish to predict). \n",
    "\n",
    "**Model prediction** is the process of making predictions for one or more samples of data for which we only input the features (not the corresponding outputs) since we assume that are trying to predict those outputs.\n",
    "1. Input the features of a sample for which we wish to make a prediction of the outputs\n",
    "2. Find the distance between the sample features and each of the training data sample features\n",
    "3. Identify the 5 nearest samples in the training data to the input sample\n",
    "4. Determine which class is most prevalent among the 5 nearest samples and assign that class to the sample\n",
    "5. Repeat steps 1-5 for each sample for which predictions are being made\n",
    "\n",
    "We'll review each step in the pseudocode above and provide some skeleton code to get you thinking through how to implement this.\n",
    "\n",
    "First, let's plan to implement this as a Python class with three methods:\n",
    "1. `__init__`. This is required of every Python class and initializes the class. In our case, this method will simply initialize the variables that will store our training data in the `fit` method.\n",
    "2. `fit`. This method will perform our training step and represents the process of fitting our model to the data.\n",
    "3. `predict`. This method will take one or more samples and make predictions of their corresponding class labels.\n",
    "\n",
    "The simplest version of skeleton code for the class we're working to create is written as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton code to write your own kNN classifier\n",
    "\n",
    "class Knn:\n",
    "# k-Nearest Neighbor class object for classification training and testing\n",
    "    def __init__(self):\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        # Save the training data to properties of this class\n",
    "        \n",
    "    def predict(self, x, k):\n",
    "        y_hat = [] # Variable to store the estimated class label for \n",
    "        # Calculate the distance from each vector in x to the training data\n",
    "        \n",
    "        # Return the estimated targets\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We'll walk through these one at a time. First, let's start with `__init__`. In this case, we can use this to initialize any variables that will be shared across the class. For example, when we run `fit`, we need to store our training data (this is a quirk of the KNN algorithm that's not the case for other machine learning techniques). This `__init__` method will be a good place to accomplish that, so let's add that in along with some documentation for it to get us started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    \"\"\"\n",
    "    Initialize the Knn class\n",
    "    self.x_train: training data features\n",
    "    self.y_train: training output labels\n",
    "    \"\"\"\n",
    "    # Save the training data to properties of this class\n",
    "    self.x_train = []\n",
    "    self.y_train = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's move on to model training and review the pseudocode for this section:\n",
    "\n",
    "Model training:\n",
    "1. Load and save the training data (features and the outputs we wish to predict). \n",
    "\n",
    "This function takes both the features and output labels as inputs and stores them in the receptical variables we initialized in `__init__`. In this section, you'll find blanks for you to fill in for this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, x, y):\n",
    "    \"\"\"\n",
    "    Save the training data to properties of this class\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: training data features\n",
    "    y: training data output labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    self.x_train = _______\n",
    "    self.y_train = _______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last component is model prediction.\n",
    "\n",
    "Model prediction has a few steps:\n",
    "1. Input the features of a sample for which we wish to make a prediction of the outputs\n",
    "2. Find the distance between the sample features and each of the training data sample features\n",
    "3. Identify the 5 nearest samples in the training data to the input sample\n",
    "4. Determine which class is most prevalent among the 5 nearest samples and assign that class to the sample\n",
    "5. Repeat steps 1-5 for each sample for which predictions are being made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining \"nearest\"\n",
    "\n",
    "Here we have some nuance in steps 3 and 4 since we need to determine the nearest samples. How do we define nearest? There are actually many ways, but for this case, we'll define it as the nearest in terms of Euclidean distance, $d()$. The Euclidean distance between two 2-dimensional vectors, $\\mathbf{x}_1 = [x_{1,1}, x_{1,2}]$ and $\\mathbf{x}_2 = [x_{2,1}, x_{2,2}]$ is:\n",
    "$$d(\\mathbf{x}_1,\\mathbf{x}_2) = \\sqrt{(x_{1,1}-x_{2,1})^2 + (x_{1,2}-x_{2,2})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we had more than 2 features for each observation? For example, if we were classifying flowers, we may use sepal width and petal width, but we could also potentially measure the sepal length and petal length as well. If we did that, we would have four total features. In this case, we would want to compare two four dimensional feature vectors $\\mathbf{x}_1 = [x_{1,1}, x_{1,2}, x_{1,4}, x_{1,4}]$ and $\\mathbf{x}_2 = [x_{2,1}, x_{2,2}, x_{2,3}, x_{2,4}]$ is:\n",
    "$$d(\\mathbf{x}_1,\\mathbf{x}_2) = \\sqrt{(x_{1,1}-x_{2,1})^2 + (x_{1,2}-x_{2,2})^2 + (x_{1,3}-x_{2,3})^2 + (x_{1,4}-x_{2,4})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For step 3 above, we need to measure this distance between the sample we are trying to make the prediction for and EVERY other sample in the training dataset. Below is skeleton code for the predict method. We will explore this more deeply in an exercise. For now, make sure you follow the logic of what is supposed to happen for all three methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x, k):\n",
    "    \"\"\"\n",
    "    Predict the class labels for the provided data\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to classify\n",
    "    k: number of neighbors to use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array(y_hat): array of predicted class labels\n",
    "    \"\"\"\n",
    "    y_hat = []  # Variable to store the estimated class labels\n",
    "\n",
    "    # Calculate the distance from each vector in x to the training data\n",
    "\n",
    "    # Loop through each of the samples for which we wish to make predictions\n",
    "\n",
    "    # For each sample, calculate the Euclidean distance to every training sample\n",
    "\n",
    "    # Determine the k nearest samples\n",
    "\n",
    "    # Determine which of the k nearest samples was most prevalent and assign that label\n",
    "\n",
    "    # Append the assigned label to y_hat\n",
    "\n",
    "    # Return the estimated targets\n",
    "    return np.array(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should be able to successfully implement the `__init__` method and the `fit` method. Before moving on, try it out for yourself. \n",
    "\n",
    "Before we move on to developing `predict` we need to gather some data to use for training and testing our KNN algorithm and discuss how to evaluate classifier performance. Those will be our next two topics."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}