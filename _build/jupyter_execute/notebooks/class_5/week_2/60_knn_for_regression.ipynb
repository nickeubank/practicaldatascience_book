{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN for regression\n",
    "\n",
    "So far, we've done a deep dive into KNN for classification. What if we want to make predictions for numerical target data, like housing prices? In that case, we would need a different approach. Instead of classification, we would use regression. Recall our example in a previous lesson about estimating house sale priceusing data on the number of bedrooms in the home, the year it was built and whether or not a swimming pool is present, as shown below in Table 1.\n",
    "\n",
    "*Table 1. Example of training data.*\n",
    "\n",
    "| $x_1$<br>Number of bedrooms| $x_2$<br>Year built | $x_3$<br>Swimming pool present? | $y$<br>Price (\\$) |\n",
    "| ----- | ------ | ---- | ---- |\n",
    "| 2 | 1965 | True  | 325,000 |\n",
    "| 1 | 1957 | False | 297,000 |\n",
    "| 3 | 2004 | False | 443,000 |\n",
    "| 4 | 2023 | True  | 502,000 |\n",
    "\n",
    "As the simplest of examples, imagine we had the training data shown in Figure 1, below showing in (A) a table of the training data (and a question mark where we want to make our prediction), and a plot of the data in (B). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Regression Example](img/regression-explained.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In Figure 1A we can see that know 4 training points and want to make a prediction for the $y$ value that corresponds to an $x$ value of 4. If you look at this, you can instantly see a reasonable answer: $y=8$. You generalize the from the data to make a prediction for a value when you don't know what the answer from the training data: this is regression.\n",
    "\n",
    "So how do we adapt our K nearest neighbors approach to work for regression problems? The transition is simple: instead of identifying the k nearest neighbors and selecting the most represented class of those k training observations, instead we simply take the average of target value of the k nearest neighbors instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/knn_regression0.png)\n",
    "\n",
    "*Figure 1. Feature space plot showing two features and the target numerical variable. The goal would be to make a prediction for the unlabeled variable $\\hat{y}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way this works is the $k$ nearest neighbors are once again identified and the target values for each are collected. Then the average of those values are used as the prediction as shown in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/knn_regression1.png)\n",
    "\n",
    "*Figure 2. Feature space plot showing the process that a prediction is made using KNN regression using $k=3$ nearest neighbors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above examples, the nearest training observations have target values of 1, 8, and 2. Therefore, the predicted value is $(1+8+2)/3=3.67$.\n",
    "\n",
    "Let's make that modification to our `Knn_classification` class to adapt it for regression. You can find a skeleton of the `Knn_regression` class below, which looks identical to our original `Knn` skeleton code for classification. There is only one modification needed to transition from classification to regression and that is, instead of calculating the class that appeared most among the neighboring training observations, since all the values are numerical, calculate the average of the values of each of the neighbors. Below is the skeleton code for the `Knn_regression` class which is identical to the classification case except for the text in caps. We'll walk through that modification then you can create your regression function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Knn_regression:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Knn class\n",
    "        self.x_train: training data\n",
    "        self.y_train: training labels\n",
    "        \"\"\"\n",
    "        # Save the training data to properties of this class\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Save the training data to properties of this class\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: training data\n",
    "        y: training labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "    def predict(self, x, k):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the provided data\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: data to classify\n",
    "        k: number of neighbors to use\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array(y_hat): array of predicted class labels\n",
    "        \"\"\"\n",
    "\n",
    "        y_hat = []  # Variable to store the estimated class labels\n",
    "\n",
    "        # Calculate the distance from each vector in x to the training data\n",
    "        # - Loop through each of the samples for which we wish to make predictions\n",
    "        #   - For each sample, calculate the Euclidean distance to every training sample\n",
    "        #   - Determine the k nearest samples\n",
    "        #   - COMPUTE THE AVERAGE OF THE K NEAREST OBSERVATIONS TARGET VALUES AND ASSIGN THAT AVERAGE AS THE PREDICTED TARGET VALUE\n",
    "        # - Append the assigned label to y_hat\n",
    "\n",
    "        # Return the estimated targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the start of your "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_average_of_neighbors(values):\n",
    "    \"\"\"\n",
    "    Computes the average of the k nearest neighbor target variable values\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: corresponding training data labels for each observation that was\n",
    "        compared when computing `dist` using `get_distance` [size N]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The target variable class of the k nearest neighbors [size k]\n",
    "    \"\"\"\n",
    "    return np.mean(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a test case to help you with this implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "labels = np.array([3, 4, 5])\n",
    "\n",
    "# Outputs\n",
    "output = get_average_of_neighbors(labels)\n",
    "correct_output = 4\n",
    "if output == correct_output:\n",
    "    print(\"PASSED\")\n",
    "else:\n",
    "    print(\"FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, complete your `Knn_regression` class and get ready to apply it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}